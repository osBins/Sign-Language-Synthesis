# -*- coding: utf-8 -*-
"""minor_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17FzPUPhTDlYy9DTdgssG5nNMIH_VjFxm
"""

import pandas as pd
import numpy as np

import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk import word_tokenize


# nltk.download('stopwords')
# nltk.download('wordnet')
# nltk.download('punkt')
# nltk.download('averaged_perceptron_tagger')
# nltk.download('omw-1.4')

def findSOVs(tokens):
    sovs = []
    verbs = [tok for tok in tokens if tok.pos_ == "VERB" and tok.dep_ != "aux"]
    for v in verbs:
        subs, verbNegated = getAllSubs(v)
        # hopefully there are subs, if not, don't examine this verb any longer
        if len(subs) > 0:
            v, objs = getAllObjs(v)
            for sub in subs:
                for obj in objs:
                    objNegated = isNegated(obj)
                    sovs.append((sub.lower_, "!" + v.lower_ if verbNegated or objNegated else v.lower_, obj.lower_))
    return sovs

data_frame=pd.read_csv("dataset_1.txt", sep="  ", header=None ,names = ["sentence"])

data_frame.head(5)

#removing stopwords 

def rem_stopwords(text):
  st_words = set(stopwords.words('english'))
  w = word_tokenize(text.lower())
  senten = [i for i in w if not  i in st_words]
  return " ".join(senten)

data_frame['sentence']=data_frame['sentence'].apply(rem_stopwords)

data_frame.head(5)

#Lemmetizing

def lem_text(text):
  wlist=[]
  lem = WordNetLemmatizer()
  senten = sent_tokenize(text)
  for s in senten :
    word = word_tokenize(s)
    for w in word : 
      wlist.append(lem.lemmatize(w))
  return " ".join(wlist)

data_frame['sentence']=data_frame['sentence'].apply(lem_text)
data_frame.head(5)

data_frame = data_frame.apply(lambda row: nltk.word_tokenize(row['sentence']), axis=1)

print(data_frame)

data_frame.head(5)

str = data_frame.to_string();

str1 = "".join(str)

print(str1)
str2 = str1.replace("-", " " )

print(str2)

str3= str2.replace(".","\n")
print(str3)

str4=str3.replace(","," ")

print(str4)

str5=str4.replace("?"," ")

print(str5)